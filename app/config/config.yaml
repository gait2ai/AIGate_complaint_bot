# AI Gate for Artificial Intelligence Applications
# Institution Complaint Management Bot: Configuration File

# ------------------------------------------
# Institution Information
# ------------------------------------------
institution:
  name: "مؤسستك" # Customizable: Institution's official name in Arabic
  name_en: "Your Institution" # Customizable: Institution's official name in English

  # Contact details that can be used in messages via {phone}, {email}, {address}
  contact:
    phone: "+9671234567" # Customizable
    email: "info@yourinstitution.org" # Customizable
    address: "صنعاء، اليمن" # Customizable: Address in Arabic
    address_en: "Sana'a, Yemen" # Customizable: Address in English

  # Other general institution details
  description: "مؤسسة تهدف إلى تقديم خدمات متميزة للمستفيدين." # Customizable
  website: "https://yourinstitution.org/" # Customizable
  timezone: "Asia/Aden" # IMPORTANT: Set to the institution's local timezone

# ------------------------------------------
# Institution Bot Specific Settings
# ------------------------------------------
institution_bot_settings:
  # Email for critical complaint notifications (if email functionality is re-enabled)
  critical_complaint_email: "alerts@yourinstitution.org" # Customizable
  # Add any other generic bot-specific settings here
  # Example: default_language_for_new_users: "ar"

# ------------------------------------------
# User-Facing Messages (Customizable Overrides)
# ------------------------------------------
custom_messages:
  ar:
    welcome: "أهلاً وسهلاً بك في نظام الشكاوى الخاص بـ {institution_name}."
    contact_details: "للتواصل: الهاتف - {phone}، البريد - {email}."
    # my_custom_greeting: "تحية خاصة من {institution_name}!"
  en:
    welcome: "Welcome to the complaint system for {institution_name}."
    contact_details: "Contact: Phone - {phone}, Email - {email}."
    # my_custom_greeting: "A special greeting from {institution_name}!"

# ------------------------------------------
# AI Models Configuration
# ------------------------------------------
ai_models:
  primary_model: "deepseek/deepseek-prover-v2:free"
  fallback_models:
    - "mistralai/mistral-small-3.1-24b-instruct:free"
    - "microsoft/phi-4-reasoning:free"
  base_url: "https://openrouter.ai/api/v1/chat/completions"
  timeout: 60
  max_tokens: 2500
  temperature: 0.3
  # --- Optional OpenRouter Parameters (uncomment and set if needed) ---
  # top_p: 0.9
  # frequency_penalty: 0.0
  # presence_penalty: 0.0
  # --- End Optional OpenRouter Parameters ---
  max_retries: 3
  retry_delay: 1.0 # seconds
  max_consecutive_failures: 5
  rate_limit_window: 60 # seconds
  min_response_length: 10
  max_response_length: 8000 # characters
  preserve_markdown: false
  fallback_responses:
    - "I apologize, but I'm currently experiencing technical difficulties. Please try again in a few moments."
    - "I'm temporarily unable to process your request due to system issues. Please contact support if this persists."
    - "There seems to be a temporary service disruption. Please try your question again shortly."

  direct_fallback_enabled: true
  huggingface_direct_provider:
    provider_type: "huggingface" # Should match key in AIHandler.providers
    api_key_env_var: "HF_API_TOKEN" # Environment variable for Hugging Face API key
    primary_model_hf: "google/gemma-7b-it" # Primary Hugging Face model
    fallback_models_hf: # Optional fallback Hugging Face models
      - "mistralai/Mistral-7B-Instruct-v0.2"
      # - "another/hf-model"
    hf_timeout: 45 # Timeout in seconds specific to Hugging Face requests
    hf_max_new_tokens: 1024 # Max new tokens for Hugging Face models
    hf_temperature: 0.7 # Temperature for Hugging Face models (can differ from OpenRouter)

# ------------------------------------------
# Cache Configuration
# ------------------------------------------
cache:
  enabled: true
  cache_dir: "app_cache" # Relative to project root
  max_size: 1000 # Max number of items in memory cache
  ttl: 3600 # Default TTL in seconds for new cache entries
  cleanup_interval: 300 # Seconds between cache cleanup runs
  categories:
    ai_response: { ttl: 1800, persistent: true, compress: true }
    # classification_keys cache category removed as keys are now from DB.
    beneficiary_profiles: { ttl: 3600, persistent: false, compress: false } # Example: Cache DB lookups for beneficiary profiles
    # Add other categories as needed, e.g.:
    # question_analysis: { ttl: 7200, persistent: true, compress: false }
    # website_research: { ttl: 86400, persistent: true, compress: true }

# ------------------------------------------
# Prompt Builder Configuration
# ------------------------------------------
prompts:
  system_template_file: "institution_system_prompt.txt" # Filename in app/config/

  # General institutional protocol information to be included in prompts
  institution_protocol_info: |
    Key Institution Complaint Handling Principles:
    - Interact with empathy, patience, and full professional respect.
    - Maintain strict confidentiality for all beneficiary information.
    - Escalate critical complaints immediately according to institution protocol.
    - Clearly explain the complaint submission process if asked.
    - Do not make promises or commitments beyond the scope of receiving the complaint.

  max_context_length: 6000 # Max characters for the {context} placeholder in the prompt
  max_prompt_length: 8000 # Max total characters for the generated system prompt
  context_truncation_strategy: 'smart' # 'smart' or 'simple'
  prompt_optimization: true # Enable/disable prompt optimization logic

# ------------------------------------------
# Logging Configuration
# ------------------------------------------
logging:
  level: "INFO" # Options: "DEBUG", "INFO", "WARNING", "ERROR", "CRITICAL"
  log_file_path: "logs/institution_bot.log" # Relative to project root
  max_file_size_mb: 10 # Max size of a single log file before rotation
  backup_count: 5 # Number of backup log files to keep
  console_output: true # Whether to also log to console (stdout)